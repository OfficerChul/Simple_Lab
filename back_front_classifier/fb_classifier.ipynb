{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "671dde78-892b-4d94-9cbd-727b68769203",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=10, micro=0, releaselevel='final', serial=0)\n",
      "Current Path: c:\\Users\\simplelab-kyochul\\Documents\\Simple_Lab\\back_front_classifier\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import time\n",
    "from datetime import timedelta\n",
    "try:\n",
    "    import h5py\n",
    "except ImportError:\n",
    "    print('h5py is not imported')\n",
    "    h5py = None\n",
    "\n",
    "print(\"Python version\")\n",
    "print(sys.version)\n",
    "print(\"Version info.\")\n",
    "print(sys.version_info)\n",
    "print(\"Current Path: \" + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62bef738-e50c-44a7-8038-26e770c0e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is NOT available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81412345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8affa86-3a02-4810-b5bd-e5530ac7ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2.png: {'face_1': {'score': 0.9994255304336548, 'facial_area': [734, 177, 827, 278], 'landmarks': {'right_eye': [765.96136, 218.37329], 'left_eye': [805.85803, 226.90715], 'nose': [781.75995, 247.61446], 'mouth_right': [759.7005, 252.14607], 'mouth_left': [789.93634, 259.15524]}}}|||len(obj): 1\n",
      "\n",
      "\n",
      "4.png: {'face_1': {'score': 0.9995377659797668, 'facial_area': [623, 133, 716, 238], 'landmarks': {'right_eye': [650.3352, 183.90204], 'left_eye': [693.8385, 184.68657], 'nose': [672.54144, 210.88965], 'mouth_right': [652.58734, 214.14919], 'mouth_left': [688.0053, 215.06595]}}}|||len(obj): 1\n",
      "\n",
      "5.png: {'face_1': {'score': 0.9973743557929993, 'facial_area': [841, 158, 908, 238], 'landmarks': {'right_eye': [859.9083, 188.20197], 'left_eye': [891.9024, 186.12212], 'nose': [877.81335, 207.16994], 'mouth_right': [865.891, 221.7853], 'mouth_left': [889.32916, 220.24525]}}}|||len(obj): 1\n",
      "\n",
      "\n",
      "7.png: {'face_1': {'score': 0.9994286298751831, 'facial_area': [711, 340, 774, 420], 'landmarks': {'right_eye': [727.4668, 376.18988], 'left_eye': [756.99097, 374.7745], 'nose': [742.5393, 394.55182], 'mouth_right': [731.6531, 402.68253], 'mouth_left': [756.0989, 401.55908]}}}|||len(obj): 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, img in enumerate(os.listdir(os.path.join(os.getcwd(), \"example_pics\"))):\n",
    "    img_path = os.path.join(os.getcwd(), f'example_pics\\{img}')\n",
    "    if img_path[img_path.rfind('.')+1:] == 'png':\n",
    "        obj = RetinaFace.detect_faces(img_path)\n",
    "        if type(obj) == dict:\n",
    "            print(f'{img}: {obj}' + '|||' + f'len(obj): {len(obj)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811dca7",
   "metadata": {},
   "source": [
    "# Code for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4052db-7871-48d2-a7e0-f39377415c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Video: 20200901_120603.MOV\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "video_num, front_vid_num, back_vid_num = 0, 0, 0\n",
    "for idx, vid in enumerate(os.listdir(os.path.join(os.getcwd(), \"example_vids\"))):\n",
    "    vid_path = os.path.join(os.getcwd(), f'example_vids\\{vid}')\n",
    "    \n",
    "    # check if the file is mov file or not\n",
    "    if not vid_path[vid_path.rfind('.') + 1:] == 'MOV':\n",
    "        print(f'{vid} is not a video.')\n",
    "        continue\n",
    "    \n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    video_num += 1\n",
    "    frame_num, front_poss, back_poss = 0, 0, 0\n",
    "    print(f'Current Video: {vid}')\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_num % 30 == 0:\n",
    "            # print(f'Detect at {frame_num / 30} second')\n",
    "            obj = RetinaFace.detect_faces(frame)\n",
    "        \n",
    "            if type(obj) == dict:\n",
    "                front_poss += 1\n",
    "            else:\n",
    "                back_poss += 1\n",
    "        \n",
    "        frame_num += 1\n",
    "        \n",
    "        \n",
    "    print(f'front_poss: {front_poss}')\n",
    "    print(f'back_poss: {back_poss}')\n",
    "    if front_poss > back_poss:\n",
    "        print(f'{vid} is a front view video.')\n",
    "        front_vid_num += 1\n",
    "    else: \n",
    "        print(f'{vid} is a back view video.')\n",
    "        back_vid_num += 1\n",
    "    print()\n",
    "\n",
    "print(time)\n",
    "elapsed = time.time() - tic\n",
    "formatted_elapsed = str(timedelta(seconds=elapsed))\n",
    "print(f'Video_num: {video_num}')\n",
    "print(f'Elapsed Time(%hh:%mm:%ss.xxx): {formatted_elapsed}')\n",
    "print(f'Result:')\n",
    "print(f'front_vid_num: {front_vid_num}')\n",
    "print(f'back_vid_num: {back_vid_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea0813f",
   "metadata": {},
   "source": [
    "# Actual Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab11394",
   "metadata": {},
   "outputs": [],
   "source": [
    "front_dir_path = r'C:\\Users\\simplelab-kyochul\\Documents\\front_view'\n",
    "back_dir_path = r'C:\\Users\\simplelab-kyochul\\Documents\\back_view'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af49192",
   "metadata": {},
   "source": [
    "## Front_View Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065e452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Video: 20200901_120603.MOV\n",
      "Current Video: 20200901_120617.MOV\n",
      "Current Video: 20200901_120631_01.MOV\n",
      "Current Video: 20200901_120642.MOV\n",
      "Current Video: 20200901_122306.MOV\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "remove_list = []\n",
    "for action_cam in os.listdir(front_dir_path):\n",
    "    new_path = os.path.join(front_dir_path, action_cam)\n",
    "    if not os.path.isdir(new_path):\n",
    "        print(f'{action_cam} is not a folder.')\n",
    "        continue\n",
    "    for action in os.listdir(new_path):\n",
    "        new_path1 = os.path.join(new_path, action)\n",
    "        if not os.path.isdir(new_path1):\n",
    "            print(f'{action} is not a folder')\n",
    "            continue\n",
    "        \n",
    "        for idx, vid in enumerate(os.listdir(new_path1)):\n",
    "            vid_path = os.path.join(new_path1, vid)\n",
    "    \n",
    "            # check if the file is mov file or not\n",
    "            if not vid_path[vid_path.rfind('.') + 1:] == 'MOV':\n",
    "                print(f'{vid} is not a video.')\n",
    "                continue\n",
    "            \n",
    "            cap = cv2.VideoCapture(vid_path)\n",
    "            \n",
    "            frame_num, front_frame, back_frame = 0, 0, 0\n",
    "            print(f'Current Video: {vid}')\n",
    "            \n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                \n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                if frame_num % 30 == 0:\n",
    "                    # print(f'Detect at {frame_num / 30} second')\n",
    "                    obj = RetinaFace.detect_faces(frame)\n",
    "                \n",
    "                    if type(obj) == dict:\n",
    "                        front_frame += 1\n",
    "                    else:\n",
    "                        back_frame += 1\n",
    "                \n",
    "                frame_num += 1\n",
    "                \n",
    "                \n",
    "            if not front_frame > back_frame:\n",
    "                remove_list.append(vid_path)\n",
    "\n",
    "for vid in remove_list:\n",
    "    os.remove(vid)\n",
    "\n",
    "print(time)\n",
    "elapsed = time.time() - tic\n",
    "formatted_elapsed = str(timedelta(seconds=elapsed))\n",
    "print(f'Video_num: {video_num}')\n",
    "print(f'Elapsed Time(%hh:%mm:%ss.xxx): {formatted_elapsed}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dddf92",
   "metadata": {},
   "source": [
    "## Back_View Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26dc735",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "video_num, front_vid_num, back_vid_num = 0, 0, 0\n",
    "for idx, vid in enumerate(os.listdir(os.path.join(os.getcwd(), \"example_vids\"))):\n",
    "    vid_path = os.path.join(os.getcwd(), f'example_vids\\{vid}')\n",
    "    \n",
    "    # check if the file is mov file or not\n",
    "    if not vid_path[vid_path.rfind('.') + 1:] == 'MOV':\n",
    "        print(f'{vid} is not a video.')\n",
    "        continue\n",
    "    \n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    video_num += 1\n",
    "    frame_num, front_poss, back_poss = 0, 0, 0\n",
    "    print(f'Current Video: {vid}')\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_num % 30 == 0:\n",
    "            # print(f'Detect at {frame_num / 30} second')\n",
    "            obj = RetinaFace.detect_faces(frame)\n",
    "        \n",
    "            if type(obj) == dict:\n",
    "                front_poss += 1\n",
    "            else:\n",
    "                back_poss += 1\n",
    "        \n",
    "        frame_num += 1\n",
    "        \n",
    "        \n",
    "    print(f'front_poss: {front_poss}')\n",
    "    print(f'back_poss: {back_poss}')\n",
    "    if front_poss > back_poss:\n",
    "        print(f'{vid} is a front view video.')\n",
    "        front_vid_num += 1\n",
    "    else: \n",
    "        print(f'{vid} is a back view video.')\n",
    "        back_vid_num += 1\n",
    "    print()\n",
    "\n",
    "print(time)\n",
    "elapsed = time.time() - tic\n",
    "formatted_elapsed = str(timedelta(seconds=elapsed))\n",
    "print(f'Video_num: {video_num}')\n",
    "print(f'Elapsed Time(%hh:%mm:%ss.xxx): {formatted_elapsed}')\n",
    "print(f'Result:')\n",
    "print(f'front_vid_num: {front_vid_num}')\n",
    "print(f'back_vid_num: {back_vid_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a9338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "71b1880c1dc035ceca007c5c92ffbc7243d617deb502d32fd5d042c1268dab7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
